# pyPaperFlow - An Automatic Paper Reading Platform

[English Version](README.md) | [Chinese Version ä¸­æ–‡ç‰ˆæœ¬](README_zh.md)

An automated platform designed to streamline the process of scientific literature reading. From retrieval and collection to structured extraction and intelligent analysis, this tool aims to assist researchers in managing and digesting large volumes of papers efficiently.

![](./figs/1.png)


## ğŸš€ Features

- **Automated Retrieval**: Search and fetch paper metadata from PubMed/Medline.
- **Full-Text Access**: Automatically download open-access full text (XML/Text) from PMC.
- **Structured Storage**:
  - **Metadata**: Stored as detailed JSON files.
  - **Lookup Table**: A CSV-based hash table for fast indexing and management.
- **Tagging System**: Manually or programmatically tag papers to create feature vectors (e.g., `relevant=1`, `reviewed=0`).
- **CLI Tool**: A user-friendly command-line interface (`pyPaperFlow`) for all operations.

## ğŸ—ï¸ Architecture Vision

The project is designed around a 7-stage workflow:

```mermaid
flowchart TD
    A[Retrieval &<br>Collection] --> B[Processing &<br>Parsing]
    B --> C[Structured<br>Extraction]
    C --> D[Deep Encoding &<br>Vectorization]
    D --> E[Dynamic Knowledge<br>Base Storage]
    E --> F[Intelligent Interaction &<br>Discovery]
    F --> G[Final Output &<br>Internalization]

    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#ffebee
    style F fill:#f1f8e9
    
    subgraph A [Stage 1: Highly Automatable]
        direction LR
        A1[Requirement Analysis] --> A2[Platform Search]
        A2 --> A3[Initial Screening]
    end

    subgraph B [Stage 2: Highly Automatable]
        direction LR
        B1[Batch Download] --> B2[Format Parsing<br>PDF/HTML/XML]
        B2 --> B3[Text Preprocessing]
    end

    subgraph C [Stage 3: Human-AI Collaboration Core]
        direction LR
        C1[Metadata Extraction] --> C2[Core Content Extraction<br>Abstract/Methods/Conclusion]
        C2 --> C3[Relation & Viewpoint Extraction]
    end

    subgraph D [Stage 4: Fully Automatable]
        direction LR
        D1[Text Slicing] --> D2[Vector Embedding]
    end

    subgraph E [Stage 5: Fully Automatable]
        direction LR
        E1[Database Storage] --> E2[Vector Indexing]
    end

    subgraph F [Stage 6: Human-AI Collaboration Core]
        direction LR
        F1[Semantic Search] --> F2[Association Rec.] --> F3[Knowledge Graph Analysis] --> F4[Review & QA]
    end

    subgraph G [Stage 7: Human-Led]
        direction LR
        G1[Critical Reading] --> G2[Inspiration Generation] --> G3[Exp. Design &<br>Paper Writing]
    end
```

### Stage Analysis & Design Philosophy

#### Stage 1: Retrieval & Collection
The starting point of the entire workflow.
- **Manual Process**: Manually entering keywords on platforms like PubMed or Google Scholar, browsing results, and saving them.
- **Automation Entry Points**:
    - **Intelligent Retrieval Agent**: Scripts using APIs or crawlers to perform periodic automated searches based on preset keywords, journal lists, or scholar tracking.
    - **Initial Screening Algorithms**: Rule-based filtering (e.g., title terms, impact factor, date range) to sort and filter results.

#### Stage 2: Processing & Parsing
Converting raw files into computer-processable plain text and metadata.
- **Automation Entry Points**:
    - **Unified Parser**: Using tools (e.g., pdfplumber, GROBID) to extract text and charts from PDFs with high precision.
    - **Metadata Enhancement**: Automatically completing full bibliographic metadata (Title, Author, DOI, etc.) and ensuring format uniformity.

#### Stage 3: Core Information Structured Extraction
The critical leap from "Text" to "Information".
- **Automation Entry Points** (Human-AI Collaboration Core):
    - **Structured Information Extraction**: Using LLMs to act as domain experts, extracting information into fixed schemas (e.g., Problem Statement, Core Methods, Key Data, Conclusions).
    - **Relation & Viewpoint Extraction**: Identifying citation intent (support/refute) and distilling core arguments.

#### Stage 4: Deep Encoding & Vectorization
Establishing mathematical representations for information.
- **Automation Entry Points**:
    - **Text Embedding**: Using Transformer models to generate high-dimensional vectors (Embeddings) for literature.
    - **Vector Storage**: Storing vectors in specialized databases (e.g., ChromaDB, Pinecone) to enable semantic retrieval.

#### Stage 5: Dynamic Knowledge Base Storage & Indexing
The "Memory" of the system.
- **Automation Entry Points**:
    - **Multi-modal Database**: A dual-storage system combining relational databases (for structured info) and vector databases (for embeddings).
    - **Automated Indexing & Association**: Automatically establishing potential links between papers (co-citation analysis, method similarity) to build the initial edges of a knowledge graph.

#### Stage 6: Intelligent Interaction & Knowledge Discovery
Active exploration using the built knowledge base.
- **Automation Entry Points** (Human-AI Collaboration Core):
    - **Semantic Search Engine**: "Ask instead of Search" - understanding query semantics to return relevant passages.
    - **Association Recommendation & Visualization**: Recommending papers based on content similarity and visualizing the academic landscape.
    - **Intelligent QA & Review Generation**: Generating structured mini-reviews based on all literature in the database.

#### Stage 7: Final Output & Internalization
Human-led, with AI as an augmentation tool.
- **Automation Entry Points**:
    - **Assisted Writing & Citation**: Real-time recommendation of relevant citations and formatting during writing.
    - **Viewpoint Collision & Inspiration**: Presenting methodological conflicts or cross-domain associations to stimulate critical thinking.

*Currently, Stages 1, 2, and parts of 4/5 (Lite version via Tagging) are implemented.*

## ğŸ“¦ Installation

```bash
git clone https://github.com/MaybeBio/pyPaperFlow.git
cd pyPaperFlow
pip install -e .
```

## ğŸ› ï¸ Usage

The platform provides a CLI tool named `paperflow`.

### 1. Search PubMed
Search for papers and get a list of PMIDs.

```bash
paperflow search "COVID-19 vaccine" --retmax 5
```

### 2. Fetch Papers
Fetch metadata for papers and save them to your local storage.

**By Query:**
```bash
paperflow fetch --query "COVID-19 vaccine" --batch-size 10
```

**By PMID List:**
Create a file `pmids.txt` with one PMID per line, then run:
```bash
paperflow fetch --file pmids.txt
```

### 3. Download Full Text
Download PMC full text for fetched papers (if available).

```bash
paperflow download-fulltext --pmid 34320283
```

### 4. Manage Tags (Feature Vectors)
Organize your papers by assigning tags. This creates a feature vector for each paper in the lookup table.

```bash
# Mark a paper as relevant
paperflow tag 34320283 relevant 1

# Mark a paper as read
paperflow tag 34320283 read 1
```

### 5. Query & Retrieve
Find papers based on your tags or retrieve full details.

**Query by Tags:**
```bash
# Find all relevant papers
paperflow query --tag relevant=1
```

**Get Paper Details:**
```bash
paperflow get 34320283
```

## ğŸ“‚ Data Structure

The platform uses a "Lite" storage approach:

-   **`paper_data/paper_lookup.csv`**: A lookup table acting as a local database.
    -   Rows: PMIDs.
    -   Columns: `json_path`, and dynamic tags (e.g., `relevant`, `topic_A`).
-   **`paper_data/papers/{pmid}.json`**: Detailed metadata and content for each paper.

We will store all datas in structures like:

output dir/year/pmid/your files


## ğŸ“ Notes on Medline Format

The fetcher parses Medline format to extract rich metadata including:
-   **PMID**: PubMed ID
-   **DP**: Date of Publication
-   **TI**: Title
-   **AB**: Abstract
-   **FAU/AU**: Authors
-   **AD**: Affiliations
-   **PT**: Publication Type (e.g., Journal Article, Review)

## ğŸ”— References & Inspiration

-   [PubMed Research Extractor](https://github.com/Proveer/pubmed-research-extractor)
-   [BioLitMiner](https://github.com/akshayoo/BioLitMiner)


## Test Cases

### ğŸ§¬ Case 1: Get PMIDs from Query

run the command:
```bash
paperflow search "alphafold3 AND conformation AND ensemble" --email YOUR_EMAIL --api-key YOUR_NCBI_API_KEY -o ./test
```
the log shows:
```bash
âœ… NCBI API Key set successfully. Rate limit increased to 10 req/s.
Now searching PubMed with query [alphafold3 AND conformation AND ensemble] at [2026-01-13 09:25:09] ...
found 16 related articles about [alphafold3 AND conformation AND ensemble] at [2026-01-13 09:25:10] ...
Retrieving 16 PMIDs from history server at [2026-01-13 09:25:10] ...
Fetching PMIDs 1 to 16 at [2026-01-13 09:25:10] ...
  -> Retrieved 16 PMIDs in this batch.
Total PMIDs retrieved: 16 out of 16 at [2026-01-13 09:25:12] ...
Found 16 PMIDs.
['41502950', '41478913', '41432299', '41249430', '41147497', '41047853', '41014267', '40950168', '40938899', '40714407', '40549150', '40490178', '39574676', '39186607', '38996889', '38995731']
PMIDs saved to ./test/searched_pmids.txt.
```
As you can see, we will print the PMIDs list for you and save it in a text file which can be used further.


### ğŸ§¬ Case 2: Fetch Metadata for pubmed papers from query or PMIDs list

If you do not have detailed PMID list and want to fetch meta information from query, run the command:
```bash
paperflow fetch -q "alphafold3 AND conformation AND ensemble" --email YOUR_EMAIL --api-key YOUR_NCBI_API_KEY -o ./test/alphafold3_ensemble
```

the log shows:
```bash
 NCBI API Key set successfully. Rate limit increased to 10 req/s.
Fetching papers for query: alphafold3 AND conformation AND ensemble
Now searching PubMed with query [alphafold3 AND conformation AND ensemble] at [2026-01-13 09:14:38] ...
found 16 related articles about [alphafold3 AND conformation AND ensemble] at [2026-01-13 09:14:39] ...
Fetching articles 1 to 16 at [2026-01-13 09:14:39] ...
  -> Retrieved 16 Medline records and 16 Xml articles. Please check whether they equal and the efetch number here with esearch count.
Error in batch Elink acheck for 16 PMIDs (Attempt 1/5): [IncompleteRead(167 bytes read)]. Retrying in 1s...
Error in batch Elink acheck for 16 PMIDs (Attempt 2/5): [IncompleteRead(167 bytes read)]. Retrying in 1s...
Error in batch Elink acheck for 16 PMIDs (Attempt 3/5): [IncompleteRead(167 bytes read)]. Retrying in 1s...
Error in batch Elink acheck for 16 PMIDs (Attempt 4/5): [IncompleteRead(167 bytes read)]. Retrying in 1s...
    [Warning] Batch Elink acheck failed for 16 PMIDs after 5 attempts at [2026-01-13 09:16:06] ...  Skipping discovery step (using default links). Error: IncompleteRead(167 bytes read)
  -> Deep mining 5 types of internal connections for 16 PMIDs at [2026-01-13 09:16:06] ...
     Fetching pubmed_pmc from pmc for 16 PMIDs at [2026-01-13 09:16:06] ...
     Fetching pubmed_pubmed from pubmed for 16 PMIDs at [2026-01-13 09:16:10] ...
     Fetching pubmed_pubmed_citedin from pubmed for 16 PMIDs at [2026-01-13 09:16:14] ...
     Fetching pubmed_pubmed_reviews from pubmed for 16 PMIDs at [2026-01-13 09:16:18] ...
     Fetching pubmed_pubmed_refs from pubmed for 16 PMIDs at [2026-01-13 09:16:24] ...
  -> Fetching external LinkOuts (Datasets, Full Text, etc.) for 16 PMIDs at [2026-01-13 09:16:27] ...
  -> Saved 41502950 to ./test/alphafold3_ensemble/2026/41502950/41502950.json
  -> Saved 41478913 to ./test/alphafold3_ensemble/2026/41478913/41478913.json
  -> Saved 41432299 to ./test/alphafold3_ensemble/2026/41432299/41432299.json
  -> Saved 41249430 to ./test/alphafold3_ensemble/2025/41249430/41249430.json
  -> Saved 41147497 to ./test/alphafold3_ensemble/2026/41147497/41147497.json
  -> Saved 41047853 to ./test/alphafold3_ensemble/2026/41047853/41047853.json
  -> Saved 41014267 to ./test/alphafold3_ensemble/2026/41014267/41014267.json
  -> Saved 40950168 to ./test/alphafold3_ensemble/2025/40950168/40950168.json
  -> Saved 40938899 to ./test/alphafold3_ensemble/2025/40938899/40938899.json
  -> Saved 40714407 to ./test/alphafold3_ensemble/2025/40714407/40714407.json
  -> Saved 40549150 to ./test/alphafold3_ensemble/2025/40549150/40549150.json
  -> Saved 40490178 to ./test/alphafold3_ensemble/2025/40490178/40490178.json
  -> Saved 39574676 to ./test/alphafold3_ensemble/2024/39574676/39574676.json
  -> Saved 39186607 to ./test/alphafold3_ensemble/2024/39186607/39186607.json
  -> Saved 38996889 to ./test/alphafold3_ensemble/2024/38996889/38996889.json
  -> Saved 38995731 to ./test/alphafold3_ensemble/2024/38995731/38995731.json
```

you can check the result here: [alphafold3_ensemble](./test/alphafold3_ensemble/)

Otherwise, if you have detailed PMID list,
run the command below:
```bash
paperflow fetch -f ./test/searched_pmids.txt  --email YOUR_EMAIL --api-key YOUR_NCBI_API_KEY -o ./test/alphafold3_ensemble_try2
```

the log shows the same way:

```bash
âœ… NCBI API Key set successfully. Rate limit increased to 10 req/s.
Fetching 16 papers from file /data2/pyPaperFlow/test/searched_pmids.txt.
Total PMIDs to fetch: 16 at [2026-01-13 09:27:13] ...
Fetching articles 1 to 16 (PMID: ['41502950', '41478913', '41432299', '41249430', '41147497', '41047853', '41014267', '40950168', '40938899', '40714407', '40549150', '40490178', '39574676', '39186607', '38996889', '38995731']) at [2026-01-13 09:27:13] ...
  -> Retrieved 16 Medline records and 16 Xml articles. Please check whether they equal and whether they match the number of this batch.
Error in batch Elink acheck for 16 PMIDs (Attempt 1/5): [IncompleteRead(167 bytes read)]. Retrying in 1s...
Error in batch Elink acheck for 16 PMIDs (Attempt 2/5): [IncompleteRead(167 bytes read)]. Retrying in 1s...
Error in batch Elink acheck for 16 PMIDs (Attempt 3/5): [IncompleteRead(167 bytes read)]. Retrying in 1s...
Error in batch Elink acheck for 16 PMIDs (Attempt 4/5): [IncompleteRead(167 bytes read)]. Retrying in 1s...
    [Warning] Batch Elink acheck failed for 16 PMIDs after 5 attempts at [2026-01-13 09:28:40] ...  Skipping discovery step (using default links). Error: IncompleteRead(167 bytes read)
  -> Deep mining 5 types of internal connections for 16 PMIDs at [2026-01-13 09:28:40] ...
     Fetching pubmed_pubmed from pubmed for 16 PMIDs at [2026-01-13 09:28:40] ...
     Fetching pubmed_pmc from pmc for 16 PMIDs at [2026-01-13 09:28:44] ...
     Fetching pubmed_pubmed_citedin from pubmed for 16 PMIDs at [2026-01-13 09:28:51] ...
     Fetching pubmed_pubmed_refs from pubmed for 16 PMIDs at [2026-01-13 09:29:01] ...
     Fetching pubmed_pubmed_reviews from pubmed for 16 PMIDs at [2026-01-13 09:29:08] ...
  -> Fetching external LinkOuts (Datasets, Full Text, etc.) for 16 PMIDs at [2026-01-13 09:29:13] ...
  -> Saved 41502950 to ./test/alphafold3_ensemble_try2/2026/41502950/41502950.json
  -> Saved 41478913 to ./test/alphafold3_ensemble_try2/2026/41478913/41478913.json
  -> Saved 41432299 to ./test/alphafold3_ensemble_try2/2026/41432299/41432299.json
  -> Saved 41249430 to ./test/alphafold3_ensemble_try2/2025/41249430/41249430.json
  -> Saved 41147497 to ./test/alphafold3_ensemble_try2/2026/41147497/41147497.json
  -> Saved 41047853 to ./test/alphafold3_ensemble_try2/2026/41047853/41047853.json
  -> Saved 41014267 to ./test/alphafold3_ensemble_try2/2026/41014267/41014267.json
  -> Saved 40950168 to ./test/alphafold3_ensemble_try2/2025/40950168/40950168.json
  -> Saved 40938899 to ./test/alphafold3_ensemble_try2/2025/40938899/40938899.json
  -> Saved 40714407 to ./test/alphafold3_ensemble_try2/2025/40714407/40714407.json
  -> Saved 40549150 to ./test/alphafold3_ensemble_try2/2025/40549150/40549150.json
  -> Saved 40490178 to ./test/alphafold3_ensemble_try2/2025/40490178/40490178.json
  -> Saved 39574676 to ./test/alphafold3_ensemble_try2/2024/39574676/39574676.json
  -> Saved 39186607 to ./test/alphafold3_ensemble_try2/2024/39186607/39186607.json
  -> Saved 38996889 to ./test/alphafold3_ensemble_try2/2024/38996889/38996889.json
  -> Saved 38995731 to ./test/alphafold3_ensemble_try2/2024/38995731/38995731.json
```

We store the meta data of the paper in a json file.
 
One example [PMID 41249430](./test/alphafold3_ensemble/2025/41249430/41249430.json) listed as below:


![alt text](./figs/41249430.png)


### ğŸ§¬ Case 3: Fetch full text data for pubmed papers from PMIDs list

If you just want to fetch full text from pmids, you can just run 
```bash
# we choose pmid 39570595 here as an example
paperflow download-fulltext  -p 39570595  --email YOUR_EMAIL --api-key YOUR_NCBI_API_KEY -o ./test/full_text
```

the log shows
```bash
âœ… NCBI API Key set successfully. Rate limit increased to 10 req/s.
Downloading full texts for 1 PMIDs from file provided PMIDs.
Fetching full text for 1 Pubmed articles at [2026-01-14 19:08:37] ...
 -> Converting Pubmed articles 1 to 1 (PMID : ['39570595']) to PMC IDs at [2026-01-14 19:08:37] ...
  -> Mapped 1 out of 1 PMIDs to valid PMC IDs. Downloading full text XML for these PMC IDs at [2026-01-14 19:08:39] ...
  -> Saved XML to ./test/full_text/2024/39570595/39570595.xml
  -> Saved parsed JSON to ./test/full_text/2024/39570595/39570595_parsed.json
  -> Saved parsed text to ./test/full_text/2024/39570595/39570595_parsed.md
```

As you can see, for full-text data, we handle it differently from metadataâ€”while metadata is simply stored in a JSON file, full-text data is output into three files with distinct formats, each serving a specific purpose:
* **{PMID}.xml**: Stores the raw XML content retrieved directly from the response, preserving the original data structure.
* **{PMID_parsed}.json**: Contains detailed, structured full-text content. This format allows for direct extraction of specific sections (e.g., introduction, results, discussion), making it ideal for quick exploration or targeted analysis of particular parts of the text.
* **{PMID_parsed}.md**: Saves the full text of the paper in Markdown format. Its clean, human-readable structure makes it well-suited for high-throughput summarization tasks using LLMs/AI tools (such as ChatGPT or other preferred models).


or you can batch download what you want 
```bash
# we use searched_pmids.txt generated by Case1
paperflow download-fulltext  -f ./test/searched_pmids.txt  --email YOUR_EMAIL --api-key YOUR_NCBI_API_KEY -o ./test/alphafold_ensemble_try3_full_text
```

the log shows 
```bash
âœ… NCBI API Key set successfully. Rate limit increased to 10 req/s.
Downloading full texts for 16 PMIDs from file /data2/pyPaperFlow/test/searched_pmids.txt.
Fetching full text for 16 Pubmed articles at [2026-01-14 19:41:58] ...
 -> Converting Pubmed articles 1 to 16 (PMID : ['41502950', '41478913', '41432299', '41249430', '41147497', '41047853', '41014267', '40950168', '40938899', '40714407', '40549150', '40490178', '39574676', '39186607', '38996889', '38995731']) to PMC IDs at [2026-01-14 19:41:58] ...
  -> Mapped 8 out of 16 PMIDs to valid PMC IDs. Downloading full text XML for these PMC IDs at [2026-01-14 19:42:14] ...
  -> Saved XML to ./test/alphafold_ensemble_try3_full_text/2024/38995731/38995731.xml
  -> Saved parsed JSON to ./test/alphafold_ensemble_try3_full_text/2024/38995731/38995731_parsed.json
  -> Saved parsed text to ./test/alphafold_ensemble_try3_full_text/2024/38995731/38995731_parsed.md
  -> Saved XML to ./test/alphafold_ensemble_try3_full_text/2024/39574676/39574676.xml
  -> Saved parsed JSON to ./test/alphafold_ensemble_try3_full_text/2024/39574676/39574676_parsed.json
  -> Saved parsed text to ./test/alphafold_ensemble_try3_full_text/2024/39574676/39574676_parsed.md
  -> Saved XML to ./test/alphafold_ensemble_try3_full_text/2025/40950168/40950168.xml
  -> Saved parsed JSON to ./test/alphafold_ensemble_try3_full_text/2025/40950168/40950168_parsed.json
  -> Saved parsed text to ./test/alphafold_ensemble_try3_full_text/2025/40950168/40950168_parsed.md
  -> Saved XML to ./test/alphafold_ensemble_try3_full_text/2025/41249430/41249430.xml
  -> Saved parsed JSON to ./test/alphafold_ensemble_try3_full_text/2025/41249430/41249430_parsed.json
  -> Saved parsed text to ./test/alphafold_ensemble_try3_full_text/2025/41249430/41249430_parsed.md
  -> Saved XML to ./test/alphafold_ensemble_try3_full_text/2025/40549150/40549150.xml
  -> Saved parsed JSON to ./test/alphafold_ensemble_try3_full_text/2025/40549150/40549150_parsed.json
  -> Saved parsed text to ./test/alphafold_ensemble_try3_full_text/2025/40549150/40549150_parsed.md
  -> Saved XML to ./test/alphafold_ensemble_try3_full_text/2025/41432299/41432299.xml
  -> Saved parsed JSON to ./test/alphafold_ensemble_try3_full_text/2025/41432299/41432299_parsed.json
  -> Saved parsed text to ./test/alphafold_ensemble_try3_full_text/2025/41432299/41432299_parsed.md
  -> Saved XML to ./test/alphafold_ensemble_try3_full_text/2025/40938899/40938899.xml
  -> Saved parsed JSON to ./test/alphafold_ensemble_try3_full_text/2025/40938899/40938899_parsed.json
  -> Saved parsed text to ./test/alphafold_ensemble_try3_full_text/2025/40938899/40938899_parsed.md
  -> Saved XML to ./test/alphafold_ensemble_try3_full_text/2026/41502950/41502950.xml
  -> Saved parsed JSON to ./test/alphafold_ensemble_try3_full_text/2026/41502950/41502950_parsed.json
  -> Saved parsed text to ./test/alphafold_ensemble_try3_full_text/2026/41502950/41502950_parsed.md
```
as you can see, not all pmids have a validated pmc id, you can try other tools for free full text extraction


### ğŸ§¬ Case 4: Fetch full paper data (including metadata and full text data) for pubmed papers from PMIDs list

Now if you want to get everything of papers you want, not just metadata or full text but BOTH!

You can simply run 
```bash
# from query 
paperflow fetch-full --query "IDR AND interaction AND deep learning" --email YOUR_EMAIL --api-key YOUR_NCBI_API_KEY -o ./test/full_paper_test

# from PMID list

```
the log shows 
```
âœ… NCBI API Key set successfully. Rate limit increased to 10 req/s.
=== Step 1: Fetching Metadata ===
Now searching PubMed with query [IDR AND interaction AND deep learning] at [2026-01-14 21:50:51] ...
found 5 related articles about [IDR AND interaction AND deep learning] at [2026-01-14 21:50:52] ...
Fetching articles 1 to 5 at [2026-01-14 21:50:52] ...
  -> Retrieved 5 Medline records and 5 Xml articles. Please check whether they equal and the efetch number here with esearch count.
Error in batch Elink acheck for 5 PMIDs (Attempt 1/3): [IncompleteRead(167 bytes read)]. Retrying in 1s...
Error in batch Elink acheck for 5 PMIDs (Attempt 2/3): [IncompleteRead(167 bytes read)]. Retrying in 1s...
    [Warning] Batch Elink acheck failed for 5 PMIDs after 3 attempts at [2026-01-14 21:51:45] ...  Skipping discovery step (using default links). Error: IncompleteRead(167 bytes read)
  -> Deep mining 5 types of internal connections for 5 PMIDs at [2026-01-14 21:51:45] ...
     Fetching pubmed_pmc from pmc for 5 PMIDs at [2026-01-14 21:51:45] ...
     Fetching pubmed_pubmed_citedin from pubmed for 5 PMIDs at [2026-01-14 21:52:00] ...
     Fetching pubmed_pubmed_reviews from pubmed for 5 PMIDs at [2026-01-14 21:52:05] ...
     Fetching pubmed_pubmed from pubmed for 5 PMIDs at [2026-01-14 21:52:09] ...
     Fetching pubmed_pubmed_refs from pubmed for 5 PMIDs at [2026-01-14 21:52:15] ...
  -> Fetching external LinkOuts (Datasets, Full Text, etc.) for 5 PMIDs at [2026-01-14 21:52:19] ...
  -> Saved 41378882 metadata to ./test/full_paper_test/2025/41378882/41378882.json
  -> Saved 40286477 metadata to ./test/full_paper_test/2025/40286477/40286477.json
  -> Saved 39763873 metadata to ./test/full_paper_test/2025/39763873/39763873.json
  -> Saved 38701796 metadata to ./test/full_paper_test/2024/38701796/38701796.json
  -> Saved 36851914 metadata to ./test/full_paper_test/2023/36851914/36851914.json

=== Step 2: Fetching Full Text ===
Fetching full text for 5 Pubmed articles at [2026-01-14 21:52:21] ...
 -> Converting Pubmed articles 1 to 5 (PMID : ['41378882', '40286477', '39763873', '38701796', '36851914']) to PMC IDs at [2026-01-14 21:52:21] ...
  -> Mapped 3 out of 5 PMIDs to valid PMC IDs. Downloading full text XML for these PMC IDs at [2026-01-14 21:52:25] ...
  -> Saved XML to ./test/full_paper_test/2025/39763873/39763873.xml
  -> Saved parsed JSON to ./test/full_paper_test/2025/39763873/39763873_parsed.json
  -> Saved parsed text to ./test/full_paper_test/2025/39763873/39763873_parsed.md
  -> Saved XML to ./test/full_paper_test/2023/36851914/36851914.xml
  -> Saved parsed JSON to ./test/full_paper_test/2023/36851914/36851914_parsed.json
  -> Saved parsed text to ./test/full_paper_test/2023/36851914/36851914_parsed.md
  -> Saved XML to ./test/full_paper_test/2025/41378882/41378882.xml
  -> Saved parsed JSON to ./test/full_paper_test/2025/41378882/41378882_parsed.json
  -> Saved parsed text to ./test/full_paper_test/2025/41378882/41378882_parsed.md

=== Step 3: Processing and Saving Metadata ===
  -> Extracted 2 URLs from full text for PMID 41378882
  -> Saved 41378882 metadata to ./test/full_paper_test/2025/41378882/41378882.json
  -> Saved 40286477 metadata to ./test/full_paper_test/2025/40286477/40286477.json
  -> Extracted 2 URLs from full text for PMID 39763873
  -> Saved 39763873 metadata to ./test/full_paper_test/2025/39763873/39763873.json
  -> Saved 38701796 metadata to ./test/full_paper_test/2024/38701796/38701796.json
  -> Extracted 29 URLs from full text for PMID 36851914
  -> Saved 36851914 metadata to ./test/full_paper_test/2023/36851914/36851914.json

```

# è¦æ³¨æ„full textä¸­è·å–çš„å…¨æ–‡é“¾æ¥ï¼Œå¯èƒ½æ˜¯æœ«å°¾å¤šäº†ä¸€äº›å…¶ä»–çš„æ•°å­—, åˆ°æ—¶å€™è®¿é—®é“¾æ¥çš„æ—¶å€™å¯ä»¥é€ä¸ªæœ«å°¾å»é™¤å†è¯•è¯•

parse soup to jsonå¯ä»¥å†ä¼˜åŒ–ä¸€ä¸‹, ç›®çš„æ˜¯ä¸ºäº†æ„å»ºæ‰€éœ€è¦çš„å·¥å…·

## ğŸ“ TODOs 

å› ä¸ºè¦åšçš„å†…å®¹æ¯”è¾ƒå¤šï¼Œè¿™é‡Œè¿˜æ˜¯æŒ‰ç…§æ€»æµç¨‹è®¾è®¡æ¥ï¼Œä¹Ÿå°±æ˜¯æŒ‰ç…§æˆ‘ä»¬åŸæœ¬çš„è®¾è®¡æ­¥éª¤æ¥ï¼Œé’ˆå¯¹æ¯ä¸€æ­¥éª¤æœ‰ä»€ä¹ˆéœ€è¦å®ç°çš„

<details>
<summary><b>Stage 1: æ£€ç´¢ä¸æ”¶é›†</b></summary>

> - [ ] ç›®å‰æ–‡çŒ®æ•°æ®åº“ä»…ä»…åªè¦†ç›–äº†pubmed, å¯¹äºå…¶ä»–é¢„å°æœ¬å¹³å°çš„æ–‡çŒ®æ•°æ®åº“å¹¶ä¸æ”¯æŒ, ä½†æ˜¯ä¸€ä¸ªäººå†™è§£æå¤ªéº»çƒ¦äº†, çœ‹åˆ°æœ‰ä¸€ä¸ªéå¸¸æ£’çš„ä»“åº“, å¯ä»¥å€ŸåŠ©å…¶å¯¹äºé™¤äº†pubmedä¹‹å¤–å…¶ä»–æ•°æ®è§£æçš„éƒ¨åˆ†ï¼Œå¯ä»¥æ•´ä¸ªåº“éƒ½importè¿›æ¥, ä½œä¸ºæ•´ä¸ªä¾èµ–çš„ä¸€éƒ¨åˆ†,å°±æ˜¯å¯ä»¥å®Œå…¨ç‹¬ç«‹, â€”â€”ã€‹å£°æ˜æ˜¯å¤–éƒ¨ä¾èµ–åº“[paperscraper](https://github.com/jannisborn/paperscraper)

</details>



## ğŸ“ Storage Design
æˆ‘ä»¬å¯ä»¥å°†æ¯ä¸€ä¸ªå‡½æ•°çš„åŠŸèƒ½ä»¥åŠæ–‡ä»¶å¤¹éƒ½è‡ªç”±è®¾è®¡ï¼Œç„¶ååœ¨è¾“å‡ºçš„æ—¶å€™å†ç»Ÿä¸€æ•´ç†


ç›®å‰æœ‰ä¸¤ç§å­˜å‚¨ç­–ç•¥ï¼Œ1ç§æ˜¯ä¸€ä¸ªpaperä½œä¸º1ä¸ªæ–‡ä»¶å¤¹ï¼Œç„¶åè¿™ä¸ªæ–‡ä»¶å¤¹é‡Œé¢å­˜æ”¾è¿™ç¯‡æ–‡çŒ®çš„metadataã€full textç­‰ï¼›
å¦å¤–ä¸€ç§æŒ‰ç…§å±‚çº§åˆ†ç±»ï¼Œå°±æ˜¯metaã€full textç­‰ä½œä¸ºä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œç„¶åè¿™ä¸ªæ–‡ä»¶å¤¹ä¸‹é¢æ¯ä¸€ä¸ªæ–‡çŒ®pmidæ”¾ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œæˆ–è€…æ˜¯ç›´æ¥æ”¾æ–‡ä»¶




âš ï¸ æš‚æ—¶é‡‡ç”¨ç¬¬ä¸€ç§

éšç€æ•°æ®é‡çš„å¢é•¿å’Œæ•°æ®ç±»å‹çš„ä¸°å¯Œï¼ˆå…ƒæ•°æ®ã€å…¨æ–‡ã€å‘é‡ã€å›¾è°±å…³ç³»ç­‰ï¼‰ï¼Œä¸€ä¸ªæ‰å¹³çš„æ–‡ä»¶å¤¹ç»“æ„ï¼ˆæ‰€æœ‰ JSON å †åœ¨ä¸€èµ·ï¼‰å¾ˆå¿«å°±ä¼šå˜å¾—ä¸å¯ç»´æŠ¤ã€‚

æ¨èçš„æ•°æ®ä»“åº“å±‚çº§è®¾è®¡
æˆ‘å»ºè®®é‡‡ç”¨ "åˆ†å±‚ + åˆ†æ¡¶ (Sharding)" çš„æ··åˆç»“æ„ã€‚

1. é¡¶å±‚è®¾è®¡ï¼šdata_repository/
è¿™æ˜¯ä½ çš„æ•°æ®ä»“åº“æ ¹ç›®å½•ï¼Œå»ºè®®ä½œä¸ºä¸€ä¸ªç‹¬ç«‹çš„ Git ä»“åº“æˆ–å•ç‹¬æŒ‚è½½çš„å­˜å‚¨å·ã€‚

```bash
data_repository/
â”œâ”€â”€ metadata/               # æ ¸å¿ƒå…ƒæ•°æ® (JSON)
â”‚   â”œâ”€â”€ 00/                 # åˆ†æ¡¶ç›®å½• (åŸºäº PMID åä¸¤ä½)
â”‚   â”‚   â”œâ”€â”€ 34320200.json
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”œâ”€â”€ fulltext/               # å…¨æ–‡æ•°æ®
â”‚   â”œâ”€â”€ pmc_xml/            # åŸå§‹ XML
â”‚   â””â”€â”€ parsed_text/        # è§£æåçš„çº¯æ–‡æœ¬
â”œâ”€â”€ vectors/                # å‘é‡æ•°æ® (å¦‚æœä¸ç”¨å‘é‡æ•°æ®åº“)
â”‚   â””â”€â”€ embeddings.npy
â”œâ”€â”€ indices/                # ç´¢å¼•ä¸æŸ¥æ‰¾è¡¨
â”‚   â”œâ”€â”€ paper_lookup.csv    # æ ¸å¿ƒæŸ¥æ‰¾è¡¨
â”‚   â””â”€â”€ tag_index.json      # æ ‡ç­¾å€’æ’ç´¢å¼•
â””â”€â”€ logs/                   # è¿è¡Œæ—¥å¿—
```


2. å…³é”®å†³ç­–ç‚¹ï¼šä¸€ä¸ª PMID ä¸€ä¸ªæ–‡ä»¶å¤¹ vs åˆ†ç±»å­˜æ”¾ï¼Ÿ
æ–¹æ¡ˆ Aï¼šä»¥ PMID ä¸ºæ ¸å¿ƒçš„æ–‡ä»¶å¤¹

```bash
papers/
  â””â”€â”€ 34320283/
      â”œâ”€â”€ metadata.json
      â”œâ”€â”€ fulltext.txt
      â””â”€â”€ fulltext.xml

```
ä¼˜ç‚¹ï¼šç‰©ç†ä¸Šèšåˆï¼Œåˆ é™¤æŸç¯‡è®ºæ–‡æ—¶éå¸¸æ–¹ä¾¿ï¼ˆç›´æ¥åˆ æ–‡ä»¶å¤¹ï¼‰ã€‚
ç¼ºç‚¹ï¼šæ–‡ä»¶ç³»ç»Ÿå‹åŠ›å¤§ï¼ˆinode æ¶ˆè€—æ˜¯ 3 å€ï¼‰ï¼Œä¸”å½“ä½ åªæƒ³â€œéå†æ‰€æœ‰å…ƒæ•°æ®â€æ—¶ï¼Œéœ€è¦é€’å½’è¿›å…¥æ¯ä¸ªæ–‡ä»¶å¤¹ï¼ŒIO æ•ˆç‡æä½ã€‚



æ–¹æ¡ˆ Bï¼šæŒ‰æ•°æ®ç±»å‹åˆ†ç±»å­˜æ”¾ï¼ˆæ¨èæ–¹æ¡ˆï¼‰
```bash
metadata/
  â””â”€â”€ 34320283.json
fulltext/
  â””â”€â”€ 34320283.txt

```

ä¼˜ç‚¹ï¼š
æ‰¹é‡å¤„ç†æå¿«ï¼šå¦‚æœè¦è®­ç»ƒ NLP æ¨¡å‹ï¼Œåªè¯» fulltext/ ç›®å½•å³å¯ï¼›å¦‚æœè¦æ„å»ºå›¾è°±ï¼Œåªè¯» metadata/ å³å¯ã€‚
ç»“æ„æ¸…æ™°ï¼šä¸åŒç±»å‹çš„æ•°æ®ç”Ÿå‘½å‘¨æœŸä¸åŒï¼ˆå…ƒæ•°æ®å¯èƒ½å¸¸æ›´æ–°ï¼Œå…¨æ–‡å¯èƒ½ä¸‹è½½ä¸€æ¬¡å°±ä¸åŠ¨äº†ï¼‰ã€‚



1. è§£å†³â€œæ–‡ä»¶å¤ªå¤šâ€çš„é—®é¢˜ï¼šåˆ†æ¡¶ (Sharding)
å½“æ–‡çŒ®æ•°é‡è¶…è¿‡ 10 ä¸‡ç¯‡æ—¶ï¼Œå•ç›®å½•ä¸‹æ–‡ä»¶è¿‡å¤šä¼šå¯¼è‡´ ls å¡æ­»ï¼Œæ–‡ä»¶ç³»ç»Ÿæ€§èƒ½ä¸‹é™ã€‚
è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ PMID çš„æœ€åä¸¤ä½ä½œä¸ºå­ç›®å½•ã€‚

PMID: 34320283 -> å­˜æ”¾åœ¨ .../83/34320283.json
è¿™æ ·æœ‰ 100 ä¸ªå­ç›®å½•ï¼ˆ00-99ï¼‰ï¼Œæ¯ä¸ªç›®å½•ä¸‹æ–‡ä»¶æ•°é‡å‡å°‘ 100 å€ï¼Œè½»æ¾æ”¯æŒåƒä¸‡çº§æ–‡çŒ®ã€‚










æˆ‘ä»¬åŸå§‹çš„åˆ†æå¦‚ä¸‹è§„åˆ’:


 All structure should be Raw Data -> Fetcher -> Paper Object -> JSON/Database -> AI Analyzer



ç°åœ¨è¦åšçš„:
1ï¼Œå…ˆæŠŠæˆ‘çš„å·¥å…·ä¸­èƒ½å¤Ÿåšçš„åšå¥½:
å°±æ˜¯ç›®å‰æˆ‘çš„å·¥å…·: stage1èƒ½å¤Ÿåšçš„æ¨¡å—åšå¥½

ï¼è¿˜å¾—å®ç°ï¼Œç»™pmidï¼Œè¿”å›å…¨æ–‡æ–‡æœ¬æ•°æ®


2, tagå°±æ˜¯å¯¹äºæ¯ä¸€ç¯‡æ–‡çŒ®çš„ä¸€ä¸ªlist
å¯¹äºæ¯ä¸€ç¯‡æ–‡çŒ®çš„tags, å¯ä»¥show/listï¼Œå¯ä»¥addï¼Œä¹Ÿå¯ä»¥remove

3, ä¸€äº›éœ€æ±‚å¯ä»¥å‚è€ƒï¼šhttps://github.com/andybrandt/mcp-simple-pubmed
ä¸€äº›è§£å†³æ–¹æ³•


4, å¦‚ä½•ä½¿ç”¨AIä»‹å…¥ï¼š
https://github.com/arokem/pubmed-gpt?tab=readme-ov-file
å¦‚ä½•åšæˆä¸€ä¸ªåˆ©ç”¨ç®€å•APIçš„å·¥å…·




5, æ•´ä½“æ–‡æ¡£æ³¨é‡Šé£æ ¼å¯ä»¥å‚è€ƒï¼š
https://github.com/iCodator/scientific_research_tool


6, æ•´ä½“å‚è€ƒå€ŸåŠ©llmå¯ä»¥åšåˆ°çš„æ•°æ®åº“å±‚é¢ï¼š
https://github.com/BridgesLab/ResearchAssistant
è‚¯å®šå¾—å€ŸåŠ©zotero



æ„å»ºè‡ªç„¶query:
https://github.com/iCodator/scientific_research_tool


åº”è¯¥æ˜¯æ¯ç¯‡æ–‡çŒ®pmidï¼Œå¯¹åº”å­˜å‚¨1ä¸ªtagçš„string listï¼Œæˆ‘ä»¬å¯ä»¥å…ˆshowä¸€ä¸‹ï¼Œå†æ·»åŠ ä¸€ä¸‹;
ç„¶åå†å‚¨å­˜å¯¹åº”çš„ä½ç½®